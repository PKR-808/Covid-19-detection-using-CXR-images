{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "train_dir = data_dir + '/train'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for the training, validation, and testing sets\n",
    "training_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                          transforms.RandomResizedCrop(80),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                               [0.229, 0.224, 0.225])])\n",
    "\n",
    "testing_transforms = transforms.Compose([transforms.Resize(82),\n",
    "                                         transforms.CenterCrop(80),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                              [0.229, 0.224, 0.225])])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "training_dataset = datasets.ImageFolder(train_dir, transform=training_transforms)\n",
    "testing_dataset = datasets.ImageFolder(test_dir, transform=testing_transforms)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x124bf6c6390>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and train your network\n",
    "# Transfer Learning\n",
    "model = models.vgg16(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze pretrained model parameters to avoid backpropogating through them\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Build custom classifier\n",
    "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 4096)),\n",
    "                                        ('relu', nn.ReLU()),\n",
    "                                        ('drop', nn.Dropout(p=0.5)),\n",
    "                                        ('fc2', nn.Linear(4096, 2)),\n",
    "                                        ('output', nn.LogSoftmax(dim=1))]))\n",
    "\n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00, -3.6206e+01],\n",
      "        [ 0.0000e+00, -4.7785e+01],\n",
      "        [ 0.0000e+00, -3.3293e+01],\n",
      "        [-1.4228e+02,  0.0000e+00],\n",
      "        [ 0.0000e+00, -8.2525e+01],\n",
      "        [-4.1389e-04, -7.7903e+00],\n",
      "        [ 0.0000e+00, -1.3741e+02],\n",
      "        [ 0.0000e+00, -1.5410e+02]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9996, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([[1.0000e+00, 1.8869e-16],\n",
      "        [1.0000e+00, 1.7671e-21],\n",
      "        [1.0000e+00, 3.4761e-15],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 1.4445e-36],\n",
      "        [9.9959e-01, 4.1372e-04],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([ True,  True,  True, False,  True,  True,  True,  True],\n",
      "       device='cuda:0')\n",
      "tensor(0.8750)\n",
      "tensor([[   0.0000, -172.1081],\n",
      "        [   0.0000, -151.4915],\n",
      "        [ -30.0661,    0.0000],\n",
      "        [-237.8398,    0.0000],\n",
      "        [   0.0000,  -37.1436],\n",
      "        [   0.0000, -214.6369],\n",
      "        [-119.2711,    0.0000],\n",
      "        [ -57.9638,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 1, 1, 0, 0, 1, 1], device='cuda:0'))\n",
      "tensor([0, 0, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [8.7591e-14, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 7.3914e-17],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [6.7086e-26, 1.0000e+00]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([ True,  True, False, False,  True,  True, False, False],\n",
      "       device='cuda:0')\n",
      "tensor(1.3750)\n",
      "tensor([[-1.5874e+01,  0.0000e+00],\n",
      "        [ 0.0000e+00, -9.2597e+01],\n",
      "        [-4.9806e-03, -5.3047e+00],\n",
      "        [-1.0110e+02,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.7847e+02],\n",
      "        [ 0.0000e+00, -1.3641e+02],\n",
      "        [ 0.0000e+00, -1.2123e+02],\n",
      "        [ 0.0000e+00, -1.7987e+02]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 1.0000, 0.9950, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'))\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([[1.2762e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 6.1022e-41],\n",
      "        [9.9503e-01, 4.9683e-03],\n",
      "        [1.2612e-44, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([False,  True,  True, False,  True,  True,  True,  True],\n",
      "       device='cuda:0')\n",
      "tensor(2.1250)\n",
      "tensor([[ 0.0000e+00, -2.3712e+02],\n",
      "        [ 0.0000e+00, -8.2838e+01],\n",
      "        [ 0.0000e+00, -4.1473e+01],\n",
      "        [ 0.0000e+00, -2.9138e+02],\n",
      "        [ 0.0000e+00, -9.7150e+01],\n",
      "        [-2.7698e+02,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.6195e+02],\n",
      "        [-2.8748e-02, -3.5636e+00]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9717],\n",
      "       device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "tensor([[1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 1.0561e-36],\n",
      "        [1.0000e+00, 9.7346e-19],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 6.4320e-43],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [9.7166e-01, 2.8338e-02]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([ True,  True,  True,  True,  True, False,  True,  True],\n",
      "       device='cuda:0')\n",
      "tensor(3.)\n",
      "tensor([[   0.0000,  -80.6397],\n",
      "        [   0.0000, -259.1319],\n",
      "        [-618.2488,    0.0000],\n",
      "        [-692.0732,    0.0000],\n",
      "        [-273.3203,    0.0000],\n",
      "        [-662.1658,    0.0000],\n",
      "        [-553.4395,    0.0000],\n",
      "        [-575.0195,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[1.0000e+00, 9.5196e-36],\n",
      "        [1.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(4.)\n",
      "tensor([[-407.3447,    0.0000],\n",
      "        [-763.2155,    0.0000],\n",
      "        [-900.5260,    0.0000],\n",
      "        [-792.2572,    0.0000],\n",
      "        [-509.7365,    0.0000],\n",
      "        [-377.2253,    0.0000],\n",
      "        [-510.1305,    0.0000],\n",
      "        [-485.5315,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(5.)\n",
      "tensor([[-582.2315,    0.0000],\n",
      "        [-480.5102,    0.0000],\n",
      "        [-770.8831,    0.0000],\n",
      "        [-125.0931,    0.0000],\n",
      "        [-603.5502,    0.0000],\n",
      "        [-595.3191,    0.0000],\n",
      "        [-653.7599,    0.0000],\n",
      "        [-319.2449,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(6.)\n",
      "tensor([[-758.8221,    0.0000],\n",
      "        [-475.7271,    0.0000],\n",
      "        [-573.7789,    0.0000],\n",
      "        [-913.2417,    0.0000],\n",
      "        [-585.3378,    0.0000],\n",
      "        [-539.8557,    0.0000],\n",
      "        [-732.2861,    0.0000],\n",
      "        [-408.9827,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(7.)\n",
      "tensor([[-465.3888,    0.0000],\n",
      "        [-639.0650,    0.0000],\n",
      "        [-536.7761,    0.0000],\n",
      "        [-678.6527,    0.0000],\n",
      "        [-305.6506,    0.0000],\n",
      "        [-724.4585,    0.0000],\n",
      "        [-601.5403,    0.0000],\n",
      "        [-475.6577,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(8.)\n",
      "tensor([[-417.3746,    0.0000],\n",
      "        [-832.8244,    0.0000],\n",
      "        [-699.1541,    0.0000],\n",
      "        [-474.7205,    0.0000],\n",
      "        [-542.5836,    0.0000],\n",
      "        [-634.1348,    0.0000],\n",
      "        [-858.6633,    0.0000],\n",
      "        [-348.8497,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(9.)\n",
      "tensor([[-510.5887,    0.0000],\n",
      "        [-537.9324,    0.0000],\n",
      "        [-469.8673,    0.0000],\n",
      "        [-326.3171,    0.0000],\n",
      "        [-342.3296,    0.0000],\n",
      "        [-473.3164,    0.0000],\n",
      "        [-580.2959,    0.0000],\n",
      "        [-326.9373,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(10.)\n",
      "tensor([[-500.4381,    0.0000],\n",
      "        [-494.7124,    0.0000],\n",
      "        [-491.0489,    0.0000],\n",
      "        [-617.4088,    0.0000],\n",
      "        [-665.2103,    0.0000],\n",
      "        [-467.9421,    0.0000],\n",
      "        [-688.9838,    0.0000],\n",
      "        [-412.7829,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(11.)\n",
      "tensor([[-381.0994,    0.0000],\n",
      "        [-870.1530,    0.0000],\n",
      "        [-321.3522,    0.0000],\n",
      "        [-752.9604,    0.0000],\n",
      "        [-538.5858,    0.0000],\n",
      "        [-354.9184,    0.0000],\n",
      "        [-503.8858,    0.0000],\n",
      "        [-768.0566,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(12.)\n",
      "tensor([[-170.9869,    0.0000],\n",
      "        [-367.2515,    0.0000],\n",
      "        [ -80.6565,    0.0000],\n",
      "        [-321.2872,    0.0000],\n",
      "        [-839.7643,    0.0000],\n",
      "        [-588.7054,    0.0000],\n",
      "        [-492.6067,    0.0000],\n",
      "        [-550.5560,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [9.3609e-36, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(13.)\n",
      "tensor([[-918.1023,    0.0000],\n",
      "        [-622.9215,    0.0000],\n",
      "        [-908.2924,    0.0000],\n",
      "        [-538.5657,    0.0000],\n",
      "        [-610.0266,    0.0000],\n",
      "        [-578.7770,    0.0000],\n",
      "        [-828.8496,    0.0000],\n",
      "        [-729.8445,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(14.)\n",
      "tensor([[-922.1694,    0.0000],\n",
      "        [-715.2611,    0.0000],\n",
      "        [-352.4589,    0.0000],\n",
      "        [-403.9079,    0.0000],\n",
      "        [-296.0772,    0.0000],\n",
      "        [-593.4314,    0.0000],\n",
      "        [-690.7393,    0.0000],\n",
      "        [-647.4531,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(15.)\n",
      "tensor([[-868.8433,    0.0000],\n",
      "        [-479.4106,    0.0000],\n",
      "        [-450.3834,    0.0000],\n",
      "        [-727.4242,    0.0000],\n",
      "        [-819.1759,    0.0000],\n",
      "        [-693.3057,    0.0000],\n",
      "        [-292.4326,    0.0000],\n",
      "        [-458.0213,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(16.)\n",
      "tensor([[-444.7539,    0.0000],\n",
      "        [-731.3081,    0.0000],\n",
      "        [-484.8311,    0.0000],\n",
      "        [-542.3571,    0.0000],\n",
      "        [-512.7731,    0.0000],\n",
      "        [-121.1735,    0.0000],\n",
      "        [-787.4341,    0.0000],\n",
      "        [-490.9669,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(17.)\n",
      "tensor([[-533.9055,    0.0000],\n",
      "        [-579.3113,    0.0000],\n",
      "        [-764.4637,    0.0000],\n",
      "        [-588.3041,    0.0000],\n",
      "        [-360.5573,    0.0000],\n",
      "        [-655.7786,    0.0000],\n",
      "        [-648.0159,    0.0000],\n",
      "        [-595.3901,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(18.)\n",
      "tensor([[-580.6377,    0.0000],\n",
      "        [-507.4539,    0.0000],\n",
      "        [-530.9292,    0.0000],\n",
      "        [-911.8955,    0.0000],\n",
      "        [-525.4417,    0.0000],\n",
      "        [-517.9738,    0.0000],\n",
      "        [-364.1323,    0.0000],\n",
      "        [-967.2856,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(19.)\n",
      "tensor([[ -858.9573,     0.0000],\n",
      "        [ -631.1033,     0.0000],\n",
      "        [ -430.2821,     0.0000],\n",
      "        [ -513.0522,     0.0000],\n",
      "        [-1016.5487,     0.0000],\n",
      "        [ -772.9581,     0.0000],\n",
      "        [ -526.2684,     0.0000],\n",
      "        [ -527.3147,     0.0000]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(20.)\n",
      "tensor([[-848.0273,    0.0000],\n",
      "        [-733.1022,    0.0000],\n",
      "        [-739.5620,    0.0000],\n",
      "        [-553.1569,    0.0000],\n",
      "        [-486.0191,    0.0000],\n",
      "        [-597.7966,    0.0000],\n",
      "        [-475.2623,    0.0000],\n",
      "        [-547.9358,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(21.)\n",
      "tensor([[-612.8424,    0.0000],\n",
      "        [-514.3586,    0.0000],\n",
      "        [-612.8831,    0.0000],\n",
      "        [-498.8144,    0.0000],\n",
      "        [-402.6440,    0.0000],\n",
      "        [-315.1490,    0.0000],\n",
      "        [-778.5986,    0.0000],\n",
      "        [-609.0867,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(22.)\n",
      "tensor([[-482.1429,    0.0000],\n",
      "        [-609.9115,    0.0000],\n",
      "        [-311.4628,    0.0000],\n",
      "        [-854.6205,    0.0000],\n",
      "        [-472.4919,    0.0000],\n",
      "        [-546.0262,    0.0000],\n",
      "        [-706.8104,    0.0000],\n",
      "        [-736.7215,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(23.)\n",
      "tensor([[-419.3088,    0.0000],\n",
      "        [-709.4514,    0.0000],\n",
      "        [-379.5334,    0.0000],\n",
      "        [-839.5239,    0.0000],\n",
      "        [-967.5045,    0.0000],\n",
      "        [-587.2219,    0.0000],\n",
      "        [-443.8544,    0.0000],\n",
      "        [-685.0853,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(24.)\n",
      "tensor([[-272.6783,    0.0000],\n",
      "        [-479.5927,    0.0000],\n",
      "        [-440.3407,    0.0000],\n",
      "        [-590.4963,    0.0000],\n",
      "        [-693.2809,    0.0000],\n",
      "        [-598.0993,    0.0000],\n",
      "        [-533.8806,    0.0000],\n",
      "        [-354.7104,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(25.)\n",
      "tensor([[-725.6678,    0.0000],\n",
      "        [-553.5073,    0.0000],\n",
      "        [-559.0496,    0.0000],\n",
      "        [-295.8360,    0.0000],\n",
      "        [-273.9047,    0.0000],\n",
      "        [-533.3276,    0.0000],\n",
      "        [-675.7165,    0.0000],\n",
      "        [-238.4020,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(26.)\n",
      "tensor([[-844.7684,    0.0000],\n",
      "        [-766.8140,    0.0000],\n",
      "        [-699.7783,    0.0000],\n",
      "        [-534.8203,    0.0000],\n",
      "        [-641.5400,    0.0000],\n",
      "        [-616.0527,    0.0000],\n",
      "        [-352.8958,    0.0000],\n",
      "        [-504.8147,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(27.)\n",
      "tensor([[-331.0748,    0.0000],\n",
      "        [-253.9082,    0.0000],\n",
      "        [-455.3140,    0.0000],\n",
      "        [-622.5745,    0.0000],\n",
      "        [-392.1866,    0.0000],\n",
      "        [-468.5203,    0.0000],\n",
      "        [-671.3168,    0.0000],\n",
      "        [-884.6032,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(28.)\n",
      "tensor([[-1013.9349,     0.0000],\n",
      "        [ -297.6214,     0.0000],\n",
      "        [ -480.1024,     0.0000],\n",
      "        [ -856.9193,     0.0000],\n",
      "        [-1056.3030,     0.0000],\n",
      "        [ -534.6293,     0.0000],\n",
      "        [ -554.2003,     0.0000],\n",
      "        [ -624.3479,     0.0000]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(29.)\n",
      "tensor([[-930.8522,    0.0000],\n",
      "        [-555.7183,    0.0000],\n",
      "        [-520.6982,    0.0000],\n",
      "        [-310.0996,    0.0000],\n",
      "        [-784.0856,    0.0000],\n",
      "        [-509.8694,    0.0000],\n",
      "        [-506.5355,    0.0000],\n",
      "        [-551.1531,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(30.)\n",
      "tensor([[-731.7949,    0.0000],\n",
      "        [-894.1564,    0.0000],\n",
      "        [-676.9697,    0.0000],\n",
      "        [-889.5906,    0.0000],\n",
      "        [-571.1809,    0.0000],\n",
      "        [-603.0245,    0.0000],\n",
      "        [-662.3130,    0.0000],\n",
      "        [-548.6840,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(31.)\n",
      "tensor([[-633.5774,    0.0000],\n",
      "        [-585.9280,    0.0000],\n",
      "        [-448.3359,    0.0000],\n",
      "        [-784.1130,    0.0000],\n",
      "        [-268.1198,    0.0000],\n",
      "        [-527.9903,    0.0000],\n",
      "        [-319.4390,    0.0000],\n",
      "        [-516.6328,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(32.)\n",
      "tensor([[ -558.9434,     0.0000],\n",
      "        [-1089.2980,     0.0000],\n",
      "        [ -487.3901,     0.0000],\n",
      "        [ -851.3379,     0.0000],\n",
      "        [ -739.3245,     0.0000],\n",
      "        [ -623.1731,     0.0000],\n",
      "        [ -536.6038,     0.0000],\n",
      "        [ -390.0392,     0.0000]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "tensor(33.)\n",
      "tensor([[-633.0430,    0.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([1.], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1], device='cuda:0'))\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([[0., 1.]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "tensor([True], device='cuda:0')\n",
      "tensor(34.)\n"
     ]
    }
   ],
   "source": [
    "# Function for the validation pass\n",
    "def validation(model, validateloader, criterion):\n",
    "    \n",
    "    val_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    for images, labels in iter(validateloader):\n",
    "\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "        output = model.forward(images)\n",
    "        val_loss += criterion(output, labels).item()\n",
    "        print(output)\n",
    "        probabilities = torch.exp(output)\n",
    "        print(labels.data)\n",
    "        print(probabilities.max(dim=1))\n",
    "        print(probabilities.max(dim=1)[1])\n",
    "        print(probabilities)\n",
    "        \n",
    "        \n",
    "        equality = (labels.data == probabilities.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        print(equality)\n",
    "        print(accuracy)\n",
    "    \n",
    "    #return val_loss, accuracy, equality, probabilities\n",
    "\n",
    "validation(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and gradient descent\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss from the function: 95.85068321228027\n",
      "Accuracy from the function: tensor(34.)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 1/5..  Training Loss: 2.885..  Validation Loss: 2.739..  Validation Accuracy: 0.971\n",
      "Val loss from the function: 35.61158275604248\n",
      "Accuracy from the function: tensor(34.3750)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 1/5..  Training Loss: 1.465..  Validation Loss: 1.017..  Validation Accuracy: 0.982\n",
      "Val loss from the function: 75.91586637496948\n",
      "Accuracy from the function: tensor(34.2500)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 1/5..  Training Loss: 5.518..  Validation Loss: 2.169..  Validation Accuracy: 0.979\n",
      "Val loss from the function: 90.06396353244781\n",
      "Accuracy from the function: tensor(33.8750)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 1/5..  Training Loss: 2.736..  Validation Loss: 2.573..  Validation Accuracy: 0.968\n",
      "Val loss from the function: 69.67939472198486\n",
      "Accuracy from the function: tensor(34.2500)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 2/5..  Training Loss: 1.462..  Validation Loss: 1.991..  Validation Accuracy: 0.979\n",
      "Val loss from the function: 138.92044305801392\n",
      "Accuracy from the function: tensor(33.6250)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 2/5..  Training Loss: 3.370..  Validation Loss: 3.969..  Validation Accuracy: 0.961\n",
      "Val loss from the function: 121.9292562007904\n",
      "Accuracy from the function: tensor(34.1250)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 2/5..  Training Loss: 2.763..  Validation Loss: 3.484..  Validation Accuracy: 0.975\n",
      "Val loss from the function: 61.02082717418671\n",
      "Accuracy from the function: tensor(34.)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 2/5..  Training Loss: 4.630..  Validation Loss: 1.743..  Validation Accuracy: 0.971\n",
      "Val loss from the function: 43.70049284957349\n",
      "Accuracy from the function: tensor(34.6250)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 3/5..  Training Loss: 2.566..  Validation Loss: 1.249..  Validation Accuracy: 0.989\n",
      "Val loss from the function: 93.23060607910156\n",
      "Accuracy from the function: tensor(34.2500)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 3/5..  Training Loss: 3.403..  Validation Loss: 2.664..  Validation Accuracy: 0.979\n",
      "Val loss from the function: 85.55994415283203\n",
      "Accuracy from the function: tensor(34.3750)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 3/5..  Training Loss: 3.835..  Validation Loss: 2.445..  Validation Accuracy: 0.982\n",
      "Val loss from the function: 54.34547805786133\n",
      "Accuracy from the function: tensor(34.6250)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 3/5..  Training Loss: 6.379..  Validation Loss: 1.553..  Validation Accuracy: 0.989\n",
      "Val loss from the function: 35.159462209790945\n",
      "Accuracy from the function: tensor(34.6250)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 4/5..  Training Loss: 3.527..  Validation Loss: 1.005..  Validation Accuracy: 0.989\n",
      "Val loss from the function: 59.24491310119629\n",
      "Accuracy from the function: tensor(34.3750)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 4/5..  Training Loss: 1.423..  Validation Loss: 1.693..  Validation Accuracy: 0.982\n",
      "Val loss from the function: 34.94225490093231\n",
      "Accuracy from the function: tensor(34.3750)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 4/5..  Training Loss: 2.717..  Validation Loss: 0.998..  Validation Accuracy: 0.982\n",
      "Val loss from the function: 26.17658567428589\n",
      "Accuracy from the function: tensor(34.5000)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 4/5..  Training Loss: 2.622..  Validation Loss: 0.748..  Validation Accuracy: 0.986\n",
      "Val loss from the function: 49.64901161193848\n",
      "Accuracy from the function: tensor(34.5000)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 5/5..  Training Loss: 2.917..  Validation Loss: 1.419..  Validation Accuracy: 0.986\n",
      "Val loss from the function: 39.60894203186035\n",
      "Accuracy from the function: tensor(34.5000)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 5/5..  Training Loss: 2.553..  Validation Loss: 1.132..  Validation Accuracy: 0.986\n",
      "Val loss from the function: 45.00991830229759\n",
      "Accuracy from the function: tensor(34.5000)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 5/5..  Training Loss: 3.133..  Validation Loss: 1.286..  Validation Accuracy: 0.986\n",
      "Val loss from the function: 38.303462982177734\n",
      "Accuracy from the function: tensor(34.6250)\n",
      "Equality from the function: tensor([True], device='cuda:0')\n",
      "Probabilities from the function: tensor([[0., 1.]], device='cuda:0')\n",
      "Length of test_loader after eval : 35\n",
      "Epoch: 5/5..  Training Loss: 2.123..  Validation Loss: 1.094..  Validation Accuracy: 0.989\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier\n",
    "train_loss, test_loss = [], []\n",
    "def train_classifier():\n",
    "        epochs = 5\n",
    "        steps = 0\n",
    "        print_every = 40\n",
    "\n",
    "        model.to('cuda')\n",
    "\n",
    "        for e in range(epochs):\n",
    "        \n",
    "            model.train()\n",
    "    \n",
    "            running_loss = 0\n",
    "    \n",
    "            for images, labels in iter(train_loader):\n",
    "        \n",
    "                steps += 1\n",
    "        \n",
    "                images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                output = model.forward(images)\n",
    "                loss = criterion(output, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                if steps % print_every == 0:\n",
    "                \n",
    "                    model.eval()\n",
    "                \n",
    "                    # Turn off gradients for validation, saves memory and computations\n",
    "                    with torch.no_grad():\n",
    "                        validation_loss, accuracy, equality, probabilities = validation(model, test_loader, criterion)\n",
    "                        train_loss.append(running_loss/len(train_loader))\n",
    "                        test_loss.append(validation_loss/len(test_loader))\n",
    "                        print(\"Val loss from the function:\", validation_loss)\n",
    "                        print(\"Accuracy from the function:\", accuracy)\n",
    "                        print(\"Equality from the function:\", equality)\n",
    "                        print(\"Probabilities from the function:\", probabilities)\n",
    "                    print(\"Length of test_loader after eval :\", len(test_loader))    \n",
    "                    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                          \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                          \"Validation Loss: {:.3f}.. \".format(validation_loss/len(test_loader)),\n",
    "                          \"Validation Accuracy: {:.3f}\".format(accuracy/len(test_loader)))\n",
    "            \n",
    "                    running_loss = 0\n",
    "                    model.train()\n",
    "                    \n",
    "train_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(test_loss, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
